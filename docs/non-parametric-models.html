<!DOCTYPE html>
<html>
  <head>
    <title>ProbMods: Non-parametric models</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" />
    <meta http-equiv="Pragma" content="no-cache" />
    <meta http-equiv="Expires" content="0" />
    <link rel="stylesheet" type="text/css" href="style.css">
    <link rel="stylesheet" type="text/css" href="webchurch/online/css/codemirror.css">
    <link rel="stylesheet" type="text/css" href="webchurch/online/css/d3.css">
    <link rel="shortcut icon" href="images/favicon.ico" />
    <script src="scripts/underscore-min.js"></script>
    <script src="scripts/jquery.js"></script>
    <link class="katex-include" rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">
    <script class="katex-include" src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.js"></script>
    <script src="scripts/cookies-0.3.1.min.js"></script>
    <script src="scripts/gg.js"></script>
    <script src="scripts/nav.js"></script>
    <script src="scripts/cosmetics.js"></script>
    <script src="scripts/md5.js"></script>
    <script src="webchurch/online/webchurch.min.js"></script>
    <script src="scripts/globals.js"></script>
    <script src="webchurch/online/vega.min.js"></script>
    <script src="scripts/new-injector.js"></script>
    <script src="scripts/headroom.min.js"></script>
  </head>
<body>
<div id="chapter-wrapper">
  <div id='header' class="headroom">
    <div id='logotype'><a href="index.html">Probabilistic Models of Cognition</a></div>
    <ul id="nav">
      <span class="nav0"><li class="all-chapters">All chapters
<ol start="0">
<a href="index.html"><li class="nonum">Index</li></a>
<a href="introduction.html"><li>Introduction</li></a>
<a href="generative-models.html"><li>Generative models</li></a>
<a href="conditioning.html"><li>Conditioning</li></a>
<a href="patterns-of-inference.html"><li>Patterns of inference</li></a>
<a href="observing-sequences.html"><li>Models for sequences of observations</li></a>
<a href="inference-about-inference.html"><li>Inference about inference</li></a>
<a href="inference-process.html"><li>Algorithms for inference</li></a>
<a href="learning-as-conditional-inference.html"><li>Learning as conditional inference</li></a>
<a href="hierarchical-models.html"><li>Hierarchical models</li></a>
<a href="occam's-razor.html"><li>Occam's Razor</li></a>
<a href="mixture-models.html"><li>Mixture models</li></a>
<a href="non-parametric-models.html"><li>Non-parametric models</li></a>
<a href="appendix-scheme.html"><li>Appendix: Scheme basics</li></a>
<a href="webchurch/online/ref.html"><li>Church Reference</li></a>
</ol>
      </li></span>
      <a class="nav0" href="/login"><li id="login-link">Login</li></a>
      <!-- <a class="nav0" href="/profile"><li id="profile-link" style='display: none'>Profile</li></a>  -->
      <a class="nav0" href="/logout"><li id="logout-link" style='display: none'>Logout</li></a>
    </ul>
    <div class="clear"></div>
  </div>

  <div id="chapter">
<h1 id="chapter-title">12. Non-parametric models</h1>
<p class='authors'>By: Noah Goodman, Timothy J. O’Donnell, Josh Tenenbaum</p>
<div class='toc'>
<div class='name'>Contents:</div>
<ul>
<li><a href="#prelude-sampling-from-a-discrete-distribution">Prelude: sampling from a discrete distribution</a></li>
<li><a href="#infinite-discrete-distributions-the-dirichlet-processes">Infinite Discrete Distributions: The Dirichlet Processes</a><ul>
<li><a href="#stochastic-memoization-with-dpmem">Stochastic Memoization with <code>DPmem</code></a></li>
<li><a href="#properties-of-dp-memoized-procedures">Properties of DP Memoized Procedures</a></li>
<li><a href="#infinite-mixture-models">Infinite Mixture Models</a></li>
</ul></li>
<li><a href="#another-view-of-the-dp-the-chinese-restaurant-process">Another View of the DP: The Chinese Restaurant Process</a><ul>
<li><a href="#example-goldwater-model-1">Example: Goldwater Model 1</a></li>
</ul></li>
<li><a href="#example-infinite-hidden-markov-models">Example: Infinite Hidden Markov Models</a></li>
<li><a href="#example-the-infinite-relational-model">Example: The Infinite Relational Model</a></li>
<li><a href="#example-crosscat">Example: CrossCat</a></li>
<li><a href="#other-non-parametric-distributions">Other Non-Parametric Distributions</a><ul>
<li><a href="#pitman-yor-distributions">Pitman-Yor Distributions</a></li>
<li><a href="#the-indian-buffet-process">The Indian Buffet Process</a></li>
</ul></li>
<li><a href="#hierarchical-combinations-of-non-parametric-processes">Hierarchical Combinations of Non-parametric Processes</a><ul>
<li><a href="#the-nested-chinese-restaurant-process">The Nested Chinese Restaurant Process</a></li>
<li><a href="#the-hierarchical-dirichlet-process">The Hierarchical Dirichlet Process</a></li>
<li><a href="#example-prototypes-and-exemplars">Example: Prototypes and Exemplars</a></li>
</ul></li>
</ul>
</div>
<p>In the chapter on <a href="mixture-models.html">Mixture Models</a> we saw a simple way to construct a model with an unbounded number of categories—simply place uncertainty over the number of categories that are ‘actually’ in the world. In this section we describe another approach which instead posits an infinite number of (mostly unused) categories actually in the world. The <em>non-parametric</em>, or <em>infinite</em>, models have a number of useful mathematical properties.</p>
<h1 id="prelude-sampling-from-a-discrete-distribution"><a href="#prelude-sampling-from-a-discrete-distribution">Prelude: sampling from a discrete distribution</a></h1>
<p>In Church the discrete distribution is a primitive—you can simply call <code>(sample-discrete '(0.2 0.3 0.1 0.4))</code>. If it wasn’t built-in and the only random primitive you could use was <code>flip</code>, how could you sample from discrete? One solution is to recursively walk down the list of probabilities, deciding whether to stop on each step. For instance, in <code>(sample-discrete '(0.2 0.3 0.1 0.4))</code> there is a 0.2 probability of stopping on the first flip, a 0.3/0.8 probability of stopping on the second flip (given that we didn’t stop on the first), and so on. We can start by turning the list of probabilities into a list of <em>residual</em> probabilities—the probability we will stop on each step, given that we haven’t stopped yet:</p>
<pre><code>(define (residuals probs)
  (if (null? probs)
      &#39;()
      (pair (/ (first probs) (sum probs))
            (residuals (rest probs)))))

(residuals &#39;(0.2 0.3 0.1 0.4))</code></pre>
<p>Now to sample from the discrete distribution we simply walk down this list, deciding when to stop:</p>
<pre><code>(define (residuals probs)
  (if (null? probs)
      &#39;()
      (pair (/ (first probs) (sum probs))
            (residuals (rest probs)))))

(define (my-sample-discrete resid)
  (if (null? resid)
      &#39;()
      (if (flip (first resid))
          1
          (+ 1 (my-sample-discrete (rest resid))))))

(hist (repeat 5000 (lambda () (my-sample-discrete (residuals &#39;(0.2 0.3 0.1 0.4))))) &quot;stop?&quot; )</code></pre>
<h1 id="infinite-discrete-distributions-the-dirichlet-processes"><a href="#infinite-discrete-distributions-the-dirichlet-processes">Infinite Discrete Distributions: The Dirichlet Processes</a></h1>
<p>We have seen several examples of mixture models where the mixture components are chosen from a multinomial distribution and the weights of the mixture components are drawn from a Dirichlet prior. Both multinomial and Dirichlet distributions are defined for fixed numbers of categories—now, imagine generalizing the combination of Dirichlet and multinomial, to a multinomial over <em>infinitely</em> many categories of components. This would solve the problem of “running out of categories,” because there would always be more categories that hadn’t yet been used for any observation.</p>
<p>Just as the Dirchlet distribution defines a prior on parameters for a multinomial with <span class="math">\(K\)</span> possible outcomes, the <em>Dirichlet process</em> defines a prior on parameters for a multinomial with <span class="math">\(K = \infty\)</span>—an infinite number of possible outcomes.</p>
<p>First, we imagine drawing an infinite sequence of samples from a beta distribution with parameters <span class="math">\(1,\ \alpha\)</span> (recall that a beta distribution defines a distribution on the interval <span class="math">\([0,1]\)</span>). We write this infinite set of draws as <span class="math">\(\left\{\beta&#39;_k\right\}_{k=1}^{\infty}\)</span>. <span class="math">\[\beta&#39;_k \sim \text{Beta}\left(1,\alpha\right)\]</span> Ultimately we would like to define a distribution on an infinite set of discrete outcomes that will represent our categories or mixture components, but we start by defining a distribution on the natural numbers. The probability of the natural number <span class="math">\(k\)</span> is given by: <span class="math">\[\beta_k = \prod_{i=1}^{k-1}\left(1-\beta&#39;_i\right)\cdot\beta&#39;_k\]</span> How can this be interpreted as a generative process? Imagine “walking” down the natural numbers in order, flipping a coin with weight <span class="math">\(\beta&#39;_i\)</span> for each one; if the coin comes up <code>false</code>, we continue to the next natural number; if the coin comes up <code>true</code>, we stop and return the current natural number. Convince yourself that the probability of getting natural number <span class="math">\(k\)</span> is given by <span class="math">\(\beta_k\)</span> above.</p>
<p>To formalize this as a Church program, we define a procedure, <code>pick-a-stick</code>, that walks down the list of <span class="math">\(\beta&#39;_k\)</span>s (called <em>sticks</em> in the statistics and machine learning literatures) and flips a coin at each one: if the coin comes up <code>true</code>, it returns the index associated with that stick, if the coin comes up <code>false</code> the procedure recurses to the next natural number.</p>
<pre><code>(define (pick-a-stick sticks J)
  (if (flip (sticks J))
      J
      (pick-a-stick sticks (+ J 1))))

(define sticks
 (mem (lambda (index) (beta 1 alpha))))</code></pre>
<p><code>pick-a-stick</code> is a higher-order procedure that takes another procedure called <code>sticks</code>, which returns the stick weight for each stick. <code>pick-a-stick</code> is also a <em>recursive</em> function—one that calls itself.</p>
<p>Notice that <code>sticks</code> uses <code>mem</code> to associate a particular draw from <code>beta</code> with each natural number. When we call it again with the same index we will get back the same stick weight. This (crucially) means that we construct the <span class="math">\(\beta&#39;_k\)</span>s only “lazily” when we need them—even though we started by imagining an infinite set of “sticks” we only ever construct a finite subset of them.</p>
<p>We can put these ideas together in a procedure called <code>make-sticks</code> which takes the <span class="math">\(\alpha\)</span> parameter as an input and returns a procedure which samples stick indices.</p>
<pre><code>(define (pick-a-stick sticks J)
  (if (flip (sticks J))
      J
      (pick-a-stick sticks (+ J 1))))

(define (make-sticks alpha)
  (let ((sticks (mem (lambda (x) (beta 1.0 alpha)))))
    (lambda () (pick-a-stick sticks 1))))

(define my-sticks (make-sticks 1))

(hist (repeat 1000 my-sticks) &quot;Dirichlet Process&quot;)</code></pre>
<p><code>my-sticks</code> samples from the natural numbers by walking down the list starting at 1 and flipping a coin weighted by a fixed <span class="math">\(\beta&#39;_k\)</span> for each <span class="math">\(k\)</span>. When the coin comes up <code>true</code> it returns <span class="math">\(k\)</span> otherwise it keeps going. It does this by drawing the individual <span class="math">\(\beta&#39;_k\)</span> <em>lazily</em>, only generating new ones when we have walked out further than furthest previous time.<ref> This way of constructing a Dirichlet Process is known as the <em>stick-breaking</em> construction and was first defined in: <br/> Sethuraman, J. (1994). A constructive definition of dirichlet priors. Statistica Sinica, 4(2):639–650. <br/> There are many other ways of defining a Dirichlet Process, one of which—the Chinese Restaurant Process—we will see below. </ref></p>
<h2 id="stochastic-memoization-with-dpmem"><a href="#stochastic-memoization-with-dpmem">Stochastic Memoization with <code>DPmem</code></a></h2>
<p>The above construction of the Dirichlet process defines a distribution over the infinite set of natural numbers. We quite often want a distribution not over the natural numbers themselves, but over an infinite set of samples from some other distribution (called the <em>base distribution</em>): we can generalize the Dirichlet process to this setting by using <code>mem</code> to associate to each natural number a draw from the base distribution.</p>
<pre><code>(define (pick-a-stick sticks J)
  (if (flip (sticks J))
      J
      (pick-a-stick sticks (+ J 1))))

(define (make-sticks alpha)
  (let ((sticks (mem (lambda (x) (beta 1.0 alpha)))))
    (lambda () (pick-a-stick sticks 1))))

(define (DPthunk alpha base-dist)
  (let ((augmented-proc (mem (lambda (stick-index) (base-dist))))
        (DP (make-sticks alpha)))
    (lambda () (augmented-proc (DP)))))


(define memoized-gaussian (DPthunk 1.0 (lambda () (gaussian 0.0 1.0))))
(density (repeat 10000 (lambda () (gaussian 0.0 1.0))) &quot;Base Distribution&quot; true)
(density (repeat 10000 memoized-gaussian) &quot;Dirichlet Process&quot; true)</code></pre>
<p>We can do a similar transformation to <em>any</em> church procedure: we associate to every argument and natural number pair a sample from the procedure, then use the Dirichlet process to define a new procedure with the same signature. In Church this useful higher-order distribution is called <code>DPmem</code>:</p>
<pre><code>(define (pick-a-stick sticks J)
  (if (flip (sticks J))
      J
      (pick-a-stick sticks (+ J 1))))

(define (make-sticks alpha)
  (let ((sticks (mem (lambda (x) (beta 1.0 alpha)))))
    (lambda () (pick-a-stick sticks 1))))

(define (DPmem alpha base-dist)
  (let ((augmented-proc (mem (lambda (args stick-index) (apply base-dist args))))
        (DP (mem (lambda (args) (make-sticks alpha)))))
    (lambda argsin
      (let ((stick-index (sample (DP argsin))))
        (augmented-proc argsin stick-index)))))

(define (geometric p)
  (if (flip p)
      0
      (+ 1 (geometric p))))

(define memoized-gaussian (DPmem 1.0 gaussian))

(density (repeat 10000 (lambda () (gaussian 0.0 1.0))) &quot;Base Distribution&quot; true)
(density (repeat 10000 (lambda () (memoized-gaussian 0.0 1.0))) &quot;Dirichlet Process&quot; true)</code></pre>
<p>In a probabilistic setting a procedure applied to some inputs may evaluate to a different value on each execution. By wrapping such a procedure in <code>mem</code> we associate a randomly sampled value with each combination of arguments. We have seen how this is useful in defining <em>random world</em> style semantics, by persistently associating individual random draws with particular <code>mem</code>’d values. However, it is also natural to consider generalizing the notion of memoization itself to the stochastic case. Since <code>DPmem</code> is a higher-order procedure that transforms a procedure into one that <em>sometimes</em> reuses it’s return values we call it a <em>stochastic memoizer</em> (<ref>Goodman, Mansighka, Roy, Bonawaitz, Tenenbaum, 2008</ref>). <!--
A stochastic memoizer wraps a stochastic procedure in another distribution, called the *memoization distribution* which tells us whether to reuse one of the previously computed values or to compute a fresh value from the underlying procedure. To accomplish this we generalize the notion of a memoization such that it we associate a **distribution** with each argument combination that we pass to the procedure.
Since, in general, a probabilistic procedure may define a distribution over an unbounded number of observations (in general an uncountable number) we need a memoization distribution that is also unbounded. This distribution should also be exchangeable. These factors lead us to define `DPmem` a stochastic generalization of `mem` which uses the Dirichlet process as a memoization distribution.
We have already shown above how to construct a Dirichlet process. All that is left to do is to associate such a process with each set of argument combinations for an arbitrary function.
Here we have defined the procedure `DPmem`. `DPmem` takes two arguments, the first is the concentration parameter of the Dirichlet process (usually written as $\alpha$, the second is some arbitrary procedure. `DPmem` first constructs an augmented version of the procedure which is passed to it. This augmented version uses `mem` to associate a particular outcome from the underlying procedure with each combination of arguments and some index called `stick-index`.
`DPmem` then constructs a Dirichlet process and associates it with the combination of arguments. It returns a procedure that when called first samples a stick index from the DP associated with the arguments and then calls the augmented procedure with the arguments and that stick index. `DPmem` can be thought of in the following way. If we had infinite time and resources we could enumerate all possible argument combinations that `proc` accepts and all the natural numbers. For all combinations of arguments plus a natural number we would draw a value from `proc` and permanently associate that value with that combination. In practice, of course, we do this lazily, only associating the new values with new combinations of arguments and stick indices as we need them.  If that combination of arguments and stick has been sampled before the previously computed value will simply be returned. Otherwise, a new value will be sampled from the underlying procedure and associated with the argument-stick combination.
--></p>
<h2 id="properties-of-dp-memoized-procedures"><a href="#properties-of-dp-memoized-procedures">Properties of DP Memoized Procedures</a></h2>
<p>A procedure in Church defines a distribution. When we wrap such a procedure in <code>DPmem</code> the resulting procedure defines a new Dirichlet process distribution. The underlying distribution associated with <code>proc</code> in the code above is called the <em>base measure</em> of the Dirichlet process and is often written <span class="math">\(\mu\)</span> or sometimes <span class="math">\(G_0\)</span>. In the following example we stochastically memoize a normal distribution.</p>
<pre><code>(define memoized-normal (DPmem 1.0 (lambda () (gaussian 0 1.0))))

(density (repeat 100 memoized-normal) &quot;DPmem normal&quot;)</code></pre>
<p>The DP is said to <em>concentrate</em> the base measure. Draws from a normal distribution are real-valued. However, draws from a DP are discrete (with probability one). By probabilistically memoizing a normal distribution we take the probability mass that the Gaussian spreads across the real line and <em>concentrate</em> it into a countable number of specific points. Compare the result of the previous computation with the result of sampling from a normal distribution itself.</p>
<pre><code>(define memoized-gaussian (DPmem 1.0 gaussian))

(density (repeat 10000 (lambda () (gaussian 0.0 1.0))) &quot;Base Distribution&quot;)
(density (repeat 10000 (lambda () (memoized-gaussian 0.0 1.0))) &quot;Dirichlet Process&quot;)</code></pre>
<p>The way that the DP concentrates the underlying base measure is illustrated in the following figure.</p>
<p><img src='images/Concentration.png' width='300' /></p>
<p>In the stick-breaking construction stick heights become shorter on average as we walk further down the number line. This means that earlier draws from the DP are more likely to be redrawn than later draws. When we use the DP to construct <code>DPmem</code> the memoized function will therefore tend to favor <em>reuse</em> of earlier computed values. Intuitively, we will use <code>DPmem</code> when we need to model reuse of samples in a scenario where we do not know in advance how many samples we need.</p>
<h2 id="infinite-mixture-models"><a href="#infinite-mixture-models">Infinite Mixture Models</a></h2>
<p>We now return to the problem of categorization with an unknown number of categories. We can use the Dirichlet process to construct a distribution over an infinite set of (potential) bags:</p>
<pre><code>(define colors &#39;(blue green red))

(define samples
 (mh-query
   200 100

   (define phi (dirichlet &#39;(1 1 1)))
   (define alpha 0.1)
   (define prototype (map (lambda (w) (* alpha w)) phi))

   (define bag-&gt;prototype (mem (lambda (bag) (dirichlet prototype))))

   ;;the prior distribution on bags is simply a DPmem of a gensym function:
   (define get-bag (DPmem 1.0 gensym))

   ;;each observation comes from one of the bags:
   (define obs-&gt;bag (mem (lambda (obs-name) (get-bag))))

   (define draw-marble
     (mem (lambda (obs-name)
            (multinomial colors (bag-&gt;prototype (obs-&gt;bag obs-name))))))

   ;;did obs1 and obs2 come from the same bag? obs1 and obs3?
   (list (equal? (obs-&gt;bag &#39;obs1) (obs-&gt;bag &#39;obs2))
         (equal? (obs-&gt;bag &#39;obs1) (obs-&gt;bag &#39;obs3)))

   (and
    (equal? &#39;red (draw-marble &#39;obs1))
    (equal? &#39;red (draw-marble &#39;obs2))
    (equal? &#39;blue (draw-marble &#39;obs3))
    (equal? &#39;blue (draw-marble &#39;obs4))
    (equal? &#39;red (draw-marble &#39;obs5))
    (equal? &#39;blue (draw-marble &#39;obs6))
    )))

(hist (map first samples) &quot;obs1 and obs2 same category?&quot;)
(hist (map second samples) &quot;obs1 and obs3 same category?&quot;)</code></pre>
<p>A model like this is called an <em>infinite mixture model</em>; in this case an infinite Dirichlet-multinomial mixture model, since the observations (the colors) come from a multinomial distribution with Dirichlet prior. The essential addition in this model is that we have <code>DPmem</code>’d a <code>gensym</code> function to provide a collection of reusable category (bag) labels:</p>
<pre><code>(define reusable-categories (DPmem 1.0 gensym))
(hist (repeat 20 reusable-categories))</code></pre>
<p>To generate our observation in this infinite mixture model we first sample a category label from the memoized <code>gensym</code>. Since the Dirichlet process tends to reuse earlier choices (more than later ones), our data will tend to cluster together in earlier components. However, there is no a priori bound on the number of latent classes, rather there is just a bias towards fewer classes. The strength of this bias is controlled by the DP concentration parameter <span class="math">\(\alpha\)</span>. When <span class="math">\(\alpha\)</span> is high, we will tolerate a larger number of classes, when it is low we will strongly favor fewer classes. In general, the number of classes grows proportional to <span class="math">\(\alpha \log(N)\)</span> where <span class="math">\(N\)</span> is the number of observations.</p>
<p>We can use this basic template to create infinite mixture models with any type of observation distribution. For instance here is an infinite Gaussian mixture model:</p>
<pre><code>(define class-distribution (DPmem 1.0 gensym))

(define object-&gt;class
  (mem (lambda (object) (class-distribution))))

(define class-&gt;gaussian-parameters
  (mem (lambda (klass) (list  (gaussian 65 10) (gaussian 0 8)))))

(define (observe object)
  (apply gaussian (class-&gt;gaussian-parameters (object-&gt;class object))))

(map observe &#39;(tom dick harry bill fred))</code></pre>
<p>There are, of course, many possible observation models that can be used in the infinite mixture. One advantage of using abstract objects to represent our data is that we can associate different observation models with different aspects of the data. For instance, we could have a model which both models height and propensity to smoke for the same set of individuals, based on their sex.</p>
<h1 id="another-view-of-the-dp-the-chinese-restaurant-process"><a href="#another-view-of-the-dp-the-chinese-restaurant-process">Another View of the DP: The Chinese Restaurant Process</a></h1>
<p>If you have looked at the literature on Bayesian models of cognition in the last few years, you will have seen many uses of a prior distribution known as the <em>Chinese Restaurant Process</em>. The Chinese Restaurant Process is an alternate, but equivalent, way to construct the Dirichlet process. The CRP is usually described as a sequential sampling scheme using the metaphor of a restaurant.</p>
<p>We imagine a restaurant with an infinite number of tables. The first customer enters the restaurant and sits at the first unoccupied table. The (<span class="math">\(N+1\)</span>)th customer enters the restaurant and sits at either an already occupied table or a new, unoccupied table, according to the following distribution. <span class="math">\[\tau^{(N+1)} |  \tau^{(1)},..., \tau^{(N)},\alpha \sim \sum_{i=1}^{K}   \frac{
                y_i
            }{
                N + \alpha
            } \delta_{\tau_{i}}  +
            \frac{
                 \alpha
            }{
                N + \alpha
            } \delta_{\tau_{K+1}}\]</span> <span class="math">\(N\)</span> is the total number of customers in the restaurant. <span class="math">\(K\)</span> is the total number of occupied tables, indexed by <span class="math">\(1 \geq i \geq K\)</span>. <span class="math">\(\tau^{(j)}\)</span> refers to the table chosen by the <span class="math">\(j\)</span>th customer. <span class="math">\(\tau_i\)</span> refers to <span class="math">\(i\)</span>th occupied table in the restaurant. <span class="math">\(y_i\)</span> is the number of customers seated at table <span class="math">\(\tau_i\)</span>; <span class="math">\(\delta_{\tau}\)</span> is the <span class="math">\(\delta\)</span>-distribution which puts all of its mass on table <span class="math">\(\tau\)</span>. <span class="math">\(\alpha \geq 0\)</span> is the <em>concentration parameter</em> of the model.</p>
<p>In other words, customers sit at an already-occupied table with probability proportional to the number of individuals at that table, or at a new table with probability controlled by the parameter <span class="math">\(\alpha\)</span>.</p>
<p>Each table has a <em>dish</em> associated with it. Each dish <span class="math">\(v\)</span> is a label on the table which is shared by all the customers at that table. When the first customer sits at a new table, <span class="math">\(\tau_i\)</span>, a dish is sampled from another distribution, <span class="math">\(\mu\)</span>, and placed on that table. This distribution, <span class="math">\(\mu\)</span>, is called the <em>base distribution</em> of the Chinese restaurant process, and is a parameter of the model. From then on, all customers who are seated at table <span class="math">\(\tau_i\)</span> share this dish, <span class="math">\(v_{\tau_i}\)</span>.</p>
<p>The following animation demonstrates the Chinese restaurant process (click on it).</p>
<center><embed width="512" height="384" src="CRP.swf" style='border: 1px solid black'></center>

<p>The CRP can be used to define a stochastic memoizer just as the Dirichlet process. We let the dish at each table be drawn from the underlying procedure. When we seat a customer we emit the dish labeling the table where the customer sat. To use a CRP as a memoization distribution we associate our underlying procedure with a set of restaurants—one for each combination of a procedure with its arguments. We let customers represent particular instances in which a procedure is evaluated, and we let the dishes labeling each table represent the values that result from those procedure applications. The base distribution which generates dishes corresponds to the underlying procedure which we have memoized.</p>
<p>When we seat a customer at an existing table, it corresponds to retrieving a value from the memory. Every customer seated at an existing table always returns the dish placed at that table when it was created. When we seat a customer at a new table it corresponds to computing a fresh value from our memoized random function and storing it as the dish at the new table. Another way of understanding the CRP is to think of it as defining a distribution over ways of partitioning <span class="math">\(N\)</span> items (customers) into <span class="math">\(K\)</span> partitions (tables), for all possible <span class="math">\(N\)</span> and <span class="math">\(K\)</span>.</p>
<p>The probability of a particular partition of <span class="math">\(N\)</span> customers over <span class="math">\(K\)</span> tables is the product of the probabilities of the <span class="math">\(N\)</span> choices made in seating those customers. It can easily be confirmed that the order in which elements are added to the partition components does not affect the probability of the final partition (i.e. the terms of the product can be rearranged in any order). Thus the distribution defined by a CRP is exchangeable.</p>
<p>The probability of a particular CRP partition can also be written down in closed form as follows. <span class="math">\[P(\vec{y})=\frac{\alpha^{K}\Gamma[\alpha]\prod_{j=0}^{K}\Gamma[y_{j}]}{\Gamma[\alpha+\sum_{j=0}^{K}y_{j}]}\]</span> Where <span class="math">\(\vec{y}\)</span> is the vector of counts of customers at each table and <span class="math">\(\Gamma(\cdot)\)</span> is the gamma function, a continuous generalization of the factorial function. This shows that for a CRP the vector of counts is sufficient.</p>
<p>As a distribution, the CRP has a number of useful properties. In particular, it implements a simplicity bias. It assigns a higher probability to partitions which (1) have fewer customers, (2) have fewer tables, and (3) for a fixed number of customers <span class="math">\(N\)</span>, assign them to the smallest number of tables.</p>
<p>Thus the CRP favors simple restaurants and implements a rich-get-richer scheme. Tables with more customers have higher probability of being chosen by later customers. These properties mean that, all else being equal, when we use the CRP as a stochastic memoizer we favor reuse of previously computed values.</p>
<!--
# The Chinese Restaurant Process and the Dirichlet Process

In the preceding part of the tutorial we discussed De Finetti's theorem. This result guarantees that any exchangeable distribution has a representation in terms of a hidden variable which renders  observations i.i.d. In the last section we introduced the Chinese restaurant process, which is an exchangeable. What is the De Finetti representation of the CRP? It turns out that the De Finetti representation of the CRP is (the stick-breaking representation of) the Dirichlet process.

Earlier we also discussed the Polya urn scheme representation of the multinomial-Dirichlet distribution. In this representation we update the counts associated with each sampled outcome after each sample. There is an obvious similarity between the Polya urn scheme and the Chinese restaurant process. In both, we update counts as we sample observations. The Dirichlet process provides a prior for infinite multinomials just as the Dirichlet distribution provides a prior for the finite case. If we explicitly integrate over all possible die weights in the case of the multinomial-Dirichlet distribution we arrive at the Polya urn scheme. Likewise, if we integrate over all possible draws of infinite sequences of sticks for the Dirichlet process we arrive at the Chinese restaurant process.

The following figure shows the generative process for a multinomial-Dirchlet and a multinomial-Dirichlet-process distribution.

<img src='crp-dp.001.png' width='400' />

We explicitly integrate over all possible draws of the finite and infinite die weights respectively.

<img src='crp-dp.002.png' width='400' />

The result is the Polya urn scheme in the finite case, and the Chinese restaurant process in the infinite case.

<img src='crp-dp.003.png' width='400' />

Church provides a higher-order procedure which implements CRP based stochastic memoization called `CRPmem`. For the reasons discussed in section [[Functional Purity, Exchangeability, and De Finetti's Theorem#XRPs|XRPs]] using `CRPmem` often leads to much more efficient inference than `DPmem`.
-->

<h2 id="example-goldwater-model-1"><a href="#example-goldwater-model-1">Example: Goldwater Model 1</a></h2>
<p>(Adapted from Goldwater, S., Griffiths, T. L., and Johnson, M. (2009). A Bayesian framework for word segmentation: Exploring the effects of context. Cognition, 112:21–54)</p>
<pre><code>(define phones &#39;(a e i o u k t p g d b s th f))
(define phone-weights (dirichlet (make-list (length phones) 1)))

(define num-words 10)

(define (sample-phone)
  (multinomial phones phone-weights))

(define (sample-phone-sequence)
  (repeat (poisson 3.0) sample-phone))

(define sample-word
  (DPmem 1.0
         (lambda ()
           (sample-phone-sequence))))

(define (sample-utterance)
  (repeat num-words sample-word))

(sample-utterance)</code></pre>
<h1 id="example-infinite-hidden-markov-models"><a href="#example-infinite-hidden-markov-models">Example: Infinite Hidden Markov Models</a></h1>
<p>Just as when we considered a mixture model over an unknown number of latent categories, we may wish to have a hidden Markov model over an unknown number of latent symbols. We can do this by again using a reusable source of state symbols:</p>
<pre><code>(define vocabulary &#39;(chef omelet soup eat work bake))

(define (get-state) (DPmem 0.5 gensym))

(define state-&gt;transition-model
  (mem (lambda (state) (DPmem 1.0 (get-state)))))

(define (transition state)
  (sample (state-&gt;transition-model state)))

(define state-&gt;observation-model
  (mem (lambda (state) (dirichlet (make-list (length vocabulary) 1)))))

(define (observation state)
  (multinomial vocabulary (state-&gt;observation-model state)))

(define (sample-words last-state)
  (if (flip 0.2)
      &#39;()
      (pair (observation last-state) (sample-words (transition last-state)))))

(sample-words &#39;start)</code></pre>
<p>This model is known as the “infinite hidden Markov model”. Notice how the transition model uses a separate DPmemoized function for each latent state: with some probability it will reuse a transition from this state, otherwise it will transition to a new state drawn from the globally shared source or state symbols—a DPmemoized <code>gensym</code>.</p>
<h1 id="example-the-infinite-relational-model"><a href="#example-the-infinite-relational-model">Example: The Infinite Relational Model</a></h1>
<p>(Adapted from: Kemp, C., Tenenbaum, J. B., Griffiths, T. L., Yamada, T. &amp; Ueda, N. (2006). Learning systems of concepts with an infinite relational model. Proceedings of the 21st National Conference on Artificial Intelligence.)</p>
<p>Much semantic knowledge is inherently <em>relational</em>. For example, verb meanings can often be formalized as relations between their arguments. The verb “give” is a three-way relation between a giver, something given, and a receiver. These relations are also inherently <em>typed</em>. For example, the giver in the relation above is typically an agent. In a preceding section, we discussed the infinite mixture models, where observations were generated from a potentially unbounded set of latent classes. In this section we introduce an extension of this model to relational data: the infinite relational model (IRM).</p>
<!--
$
\[ \left( \begin{array}{ccccc}
1 & 0 & 0 & 1 & 0 \\
1 & 1 & 0 & 1 & 0 \\
1 & 0 & 0 & 1 & 0 \\
0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 \\
\end{array} \right)\]
$
-->

<p>Given some relational data, the IRM learns to cluster objects into classes such that whether or not the relation holds depends on the <em>pair</em> of object classes. For instance, we can imagine trying to infer social groups from the relation of who talks to who:</p>
<pre><code>(define samples
  (mh-query
   300 100

   (define class-distribution (DPmem 1.0 gensym))

   (define object-&gt;class
     (mem (lambda (object) (class-distribution))))

   (define classes-&gt;parameters
     (mem (lambda (class1 class2) (beta 0.5 0.5))))

   (define (talks object1 object2)
     (flip (classes-&gt;parameters (object-&gt;class object1) (object-&gt;class object2))))

   (list (equal? (object-&gt;class &#39;tom) (object-&gt;class &#39;fred))
         (equal? (object-&gt;class &#39;tom) (object-&gt;class &#39;mary)))

   (and (talks &#39;tom &#39;fred)
        (talks &#39;tom &#39;jim)
        (talks &#39;jim &#39;fred)
        (not (talks &#39;mary &#39;fred))
        (not (talks &#39;mary &#39;jim))
        (not (talks &#39;sue &#39;fred))
        (not (talks &#39;sue &#39;tom))
        (not (talks &#39;ann &#39;jim))
        (not (talks &#39;ann &#39;tom))
        (talks &#39;mary &#39;sue)
        (talks &#39;mary &#39;ann)
        (talks &#39;ann &#39;sue)
        )))

(hist (map first samples) &quot;tom and fred in same group?&quot;)
(hist (map second samples) &quot;tom and mary in same group?&quot;)</code></pre>
<p>We see that the model invents two classes (the “boys” and the “girls”) such that the boys talk to each other and the girls talk to each other, but girls don’t talk to boys. Note that there is much missing data (unobserved potential relations) in this example.</p>
<h1 id="example-crosscat"><a href="#example-crosscat">Example: CrossCat</a></h1>
<p>(Adapted from: Shafto, P. Kemp, C., Mansignhka, V., Gordon, M., and Tenenbaum, J. B. (2006). Learning cross-cutting systems of categories. Proceedings of the Twenty-Eighth Annual Conference of the Cognitive Science Society.)</p>
<p>Often we have data where each object is associated with a number of features. In many cases, we can predict how these features generalize by assigning the objects to classes and predicting feature values on a class-by-class basis. In fact, we can encode this kind of structure using the IRM above if we interpret the relations as the presence of absence of a feature. However, in some cases this approach does not work because objects can be categorized into multiple categories, and different features are predicted by different category memberships.</p>
<p>For example, imagine we have some list of foods like: eggs, lobster, oatmeal, etc., and some list of features associated with these foods, such as: dairy, inexpensive, dinner, eaten with soup, etc. These features depend on different systems of categories that foods fall into, for example, one set of features may depend on the time of day that the foods are eaten, while another set may depend on whether the food is animal or vegetable based. CrossCat is a model designed to address these problems. The idea behind CrossCat is that features themselves cluster into <em>kinds</em>. Within each kind, particular objects will cluster into categories which predict the feature values for those objects in the kind. Thus CrossCat is a kind of hierarchical extension to the IRM which takes into account multiple domains of featural information.</p>
<!--

(define objects '(Eggs Lobster Oatmeal Pancakes Rice Spaghetti Steak Yogurt))
(define features '("dairy" "inexpensive" "meat" "breakfast" "food"
                           "comes in a box" "dinner food" "eaten with soup"
                           "grain" "high in calories" "high in protein"
                           "high in starch" "kept refrigerated" "made with milk"
                           "served with coffee" "served with wine" "water added"))
-->

<pre><code>(define kind-distribution (DPmem 1.0 (make-gensym &quot;kind&quot;)))

(define feature-&gt;kind
  (mem (lambda (feature) (kind-distribution))))

(define kind-&gt;class-distribution
  (mem (lambda (kind) (DPmem 1.0 (make-gensym &quot;class&quot;)))))

(define feature-kind/object-&gt;class
  (mem (lambda (kind object) (sample (kind-&gt;class-distribution kind)))))

(define class-&gt;parameters
  (mem (lambda (object-class) (beta 1 1))))

(define (observe object feature)
  (flip (class-&gt;parameters (feature-kind/object-&gt;class (feature-&gt;kind feature) object))))

(observe &#39;eggs &#39;breakfast)</code></pre>
<h1 id="other-non-parametric-distributions"><a href="#other-non-parametric-distributions">Other Non-Parametric Distributions</a></h1>
<p>The Dirichlet Process is the best known example of a <em>non-parametric distribution</em>. The term <em>non-parametric</em> refers to statistical models whose size or complexity can grow with the data, rather than being specified in advance (sometimes these are called <em>infinite models</em>, since they assumes an infinite, not just unbounded number of categories). There a number of other such distributions that are worth knowing.</p>
<h2 id="pitman-yor-distributions"><a href="#pitman-yor-distributions">Pitman-Yor Distributions</a></h2>
<p>Many models in the literature use a small generalization of the CRP known as the Pitman-Yor process (PYP). The Pitman-Yor process is identical to the CRP except for having an extra parameter, <span class="math">\(a\)</span>, which introduces a dependency between the probability of sitting at a new table and the number of tables already occupied in the restaurant.</p>
<p>The process is defined as follows. The first customer enters the restaurant and sits at the first table. The (<span class="math">\(N+1\)</span>)th customer enters the restaurant and sits at either an already occupied table or a new one, according to the following distribution. <span class="math">\[
  \tau^{(N+1)} |  \tau^{(1)},...,\tau^{(N)}, a, b \sim \sum_{i=1}^{K}  \frac{
                y_i - a
            }{
                N + b
            } \delta_{\tau_{i}} +
            \frac{
                Ka + b
            }{
                N + b
            } \delta_{\tau_{K+1}}
\]</span> Here all variables are the same as in the CRP, except for <span class="math">\(a\)</span> and <span class="math">\(b\)</span>. <span class="math">\(b \geq 0\)</span> corresponds to the CRP <span class="math">\(\alpha\)</span> parameter. <span class="math">\(0 \leq a \leq 1\)</span> is a new <em>discount</em> parameter which moves a fraction of a unit of probability mass from each occupied table to the new table. When it is <span class="math">\(1\)</span>, every customer will sit at their own table. When it is <span class="math">\(0\)</span> the distribution becomes the single-parameter CRP. The <span class="math">\(a\)</span> parameter can be thought of as controlling the <em>productivity</em> of a restaurant: how much sitting at a new table depends on how many tables already exist. On average, <span class="math">\(a\)</span> will be the limiting proportion of tables in the restaurant which have only a single customer. The <span class="math">\(b\)</span> parameter controls the rate of growth of new tables in relation to the total number of customers <span class="math">\(N\)</span> as before.</p>
<p>Like the CRP, the sequential sampling scheme outlined above generates a distribution over partitions for unbounded numbers of objects. Given some vector of table counts <span class="math">\(\vec{y}\)</span>, A closed-form expression for this probability can be given as follows. First, define the following generalization of the factorial function, which multiples <span class="math">\(m\)</span> integers in increments of size <span class="math">\(a\)</span> starting at <span class="math">\(x\)</span>. <span class="math">\[
    [x]_{m,s} =
    \begin{cases}
        1 &amp; \text{for } m=0 \\
        x(x+s)...(x+(m-1)s)&amp; \text{for }  m &gt; 0
    \end{cases}
\]</span> Note that <span class="math">\([1]_{m,1} = m!\)</span>. The probability of the partition given by the count vector, <span class="math">\(\vec{y}\)</span>, is defined by: <span class="math">\[
    P( \vec{y} \mid a, b) = \frac{[b+a]_{K-1,a}}{[b+1]_{N-1,1}} \prod_{i=1}^{K}[1-a]_{y_i-1,1}
\]</span> It is easy to confirm that in the special case of <span class="math">\(a = 0\)</span> and <span class="math">\(b &gt;0\)</span>, this reduces to the closed form for CRP by noting that <span class="math">\([1]_{m,1} = m!  = \Gamma[m+1]\)</span>. In what follows, we will assume that we have a higher-order function <code>PYmem</code> which takes three arguments <code>a</code>, <code>b</code>, and <code>proc</code> and returns the PYP-memoized version of <code>proc</code>.</p>
<h2 id="the-indian-buffet-process"><a href="#the-indian-buffet-process">The Indian Buffet Process</a></h2>
<p>The Indian Buffet Process is an infinite distribution on <em>sets</em> of draws from a base measure (rather than a single draw as in the CRP).</p>
<h1 id="hierarchical-combinations-of-non-parametric-processes"><a href="#hierarchical-combinations-of-non-parametric-processes">Hierarchical Combinations of Non-parametric Processes</a></h1>
<p>In the <a href="hierarchical-models.html">Hierarchical Models</a> chapter, we explored how additional levels of abstraction can lead to important effects in learning dynamics, such as transfer learning and the blessing of abstraction. In this section, we talk about two ways in which hierarchical non-parametric models can be built.</p>
<h2 id="the-nested-chinese-restaurant-process"><a href="#the-nested-chinese-restaurant-process">The Nested Chinese Restaurant Process</a></h2>
<p>We have seen how the Dirichlet Process/CRP can be used to learn mixture models where the number of categories is infinite. However, the categories associated with each table or stick in the DP/CRP are unstructured, whereas real life categories have complex relationships with one another. For example, they are often organized into hierarchies: a German shepherd is a type of dog, which is a type of animal, which is type of living thing, and so on.</p>
<p>In <a href="hierarchical-models.html#example-one-shot-learning-of-visual-categories">Example: One-shot learning of visual categories</a>, we saw how such hierarchies could lead to efficient one-shot learning, but we did not talk about how such a hierarchy itself could be learned. The <em>Nested Chinese Restaurant Process</em> (nCRP) is one way of doing this. (Blei, D. M., Griffiths, T. L., Jordan, M. I., and Tenenbaum, J. B, 2004. Hierarchical topic models and the nested chinese restaurant process. In Advances in Neural Information Processing Systems 16). The idea behind the nCRP is that tables in a CRP, which typically represent categories, can refer to <em>other restaurants</em> that represent lower-level categories.</p>
<pre><code>(define top-gensym (make-gensym &quot;t&quot;))
(define top-level-category (DPmem 1.0 top-gensym))

(define subordinate-gensym (make-gensym &quot;s&quot;))
(define subordinate-category
  (DPmem 1.0
         (lambda (parent-category)
           (list (subordinate-gensym) parent-category))))

(define (sample-category) (subordinate-category (top-level-category)))

(table (pair (list &quot;subordinate&quot; &quot;top&quot;)
             (repeat 10 sample-category)))</code></pre>
<p>Each call to <code>sample-category</code> returns a list that consists of a subordinate-level category followed by the corresponding top-level category. These categories are represented by gensyms, and, because they are drawn from a DP-memoized version of gensym, there is no <em>a priori</em> limit on the number of possible categories at each level.</p>
<p>The nCRP gives us a way of constructing unbounded sets of hierarchically nested categories, but how can we use such structured categories to generate data? The code below shows one way:</p>
<pre><code>(define top-gensym (make-gensym &quot;t&quot;))
(define possible-observations &#39;(a b c d e f g))

(define top-level-category (DPmem 1.0 top-gensym))
(define top-level-category-&gt;parameters
  (mem (lambda (cat) (dirichlet (make-list (length possible-observations) 1.0)))))

(define subordinate-gensym (make-gensym &quot;s&quot;))
(define subordinate-category
  (DPmem 1.0
         (lambda (parent-category)
           (list (subordinate-gensym) parent-category))))

(define subordinate-category-&gt;parameters
  (mem (lambda (cat) (dirichlet (top-level-category-&gt;parameters (second cat)))))) 

(define (sample-category) (subordinate-category (top-level-category)))

(define (sample-observation) (multinomial possible-observations (subordinate-category-&gt;parameters (sample-category))))

(repeat 10 sample-observation)</code></pre>
<p>This code shows a model where each category is associated with a multinomial distribution over the following possible observations: <code>(a b c d e f g)</code>. This distribution is drawn from a Dirichlet prior for each subordinate-level category. However, the <em>pseudocounts</em> for the Dirichlet distribution for each subordinate-level category are drawn from another Dirichlet distribution which is associated with the <strong>top-level</strong> category—all of the subordinate level categories which share a top-level category also have similar distributions over observations.</p>
<p>In fact, the model presented in <a href="hierarchical-models.html#example-one-shot-learning-of-visual-categories">Example: One-shot learning of visual categories</a> works in the same way, except that each category is associated with Gaussian distribution and the mean and variance parameters are shared between subordinate level categories.</p>
<h2 id="the-hierarchical-dirichlet-process"><a href="#the-hierarchical-dirichlet-process">The Hierarchical Dirichlet Process</a></h2>
<p>In the last section, we saw an example where subordinate-level categories drew their hyperparameters from a shared Dirichlet distribution. It is also possible to build a similar model using a Dirichlet Process at each level. This model is known as the <em>Hierarchical Dirichlet Process</em> (HDP). (Teh, Y. W., Jordan, M. I., Beal, M. J., and Blei, D. M. (2006). Hierarchical dirichlet processes. Journal of the American Statistical Association, 101(476):1566–1581.)</p>
<pre><code>(define base-measure (lambda () (poisson 20)))
(define top-level  (DPmem 10.0 base-measure))
(define sample-observation
  (DPmem 1.0
         (lambda (component)
           (top-level))))

(hist (repeat 1000 base-measure) &quot;Draws from Base Measure (poisson 20)&quot;)
(hist (repeat 1000 top-level) &quot;Draws from Top Level DP&quot;)
(hist (repeat 1000 (lambda () (sample-observation &#39;component1))) &quot;Draws from Component DP 1&quot;)
(hist (repeat 1000 (lambda () (sample-observation &#39;component2))) &quot;Draws from Component DP 2&quot;)
(hist (repeat 1000 (lambda () (sample-observation &#39;component3))) &quot;Draws from Component DP 3&quot;)</code></pre>
<p>In an HDP, there are several component Dirichlet Processes (labeled here as <code>component1</code>, <code>component2</code>, etc.). These component DPs all share another DP (called <code>top-level</code>) as their base measure.</p>
<p>In the example above, we have used a <code>poisson</code> distribution as the base measure. The top-level DP concentrates this distribution into a number of points. Each of the component DPs then further concentrate this distribution—sharing the points chosen by the top-level DP, but further concentrating it, each in their own way.</p>
<p>A natural move is to combine the nCRP and HDP: the nCRP can be used to sample an unbounded set of hierarchically structured categories, and the HDP can be used to make these categories share observations in interesting ways.</p>
<pre><code>(define top-gensym (make-gensym &quot;t&quot;))
(define top-level-category (DPmem 1.0 top-gensym))

(define root-category (DPmem 10.0 (lambda () (poisson 20))))

(define sample-from-top-level-category (DPmem 1.0 (lambda (cat) (root-category))))

(define subordinate-gensym (make-gensym &quot;s&quot;))
(define subordinate-category
  (DPmem 1.0
         (lambda (parent-category)
           (list (subordinate-gensym) parent-category))))

(define (sample-category) (subordinate-category (top-level-category)))

(define sample-observation
  (DPmem 1.0
         (lambda (cat)
           (sample-from-top-level-category (rest cat)))))

(repeat
 10
 (lambda ()
   (let* ([category (sample-category)]
          [subordinate (first category)]
          [top (second category)]
          [h1 (hist (repeat 1000 (lambda () (sample-observation category)))
                    (string-append  &quot;Top Level: &quot; top &quot;, Subordinate Level: &quot; subordinate))]
          [h2 (hist (repeat 1000 (lambda () (sample-from-top-level-category top)))
                    (string-append  &quot;Top Level: &quot; top))]
          [h3 (hist (repeat 1000 (lambda () (sample-observation category)))
                    &quot;Root Category&quot;)])
     &#39;dummy)))</code></pre>
<p>Note that the nCRP and the HDP represent very different ways to construct distributions with hierarchically arranged non-parametric distributions. The nCRP builds a hiearchy of category types, while the HDP shares observations between multiple DPs.</p>
<h2 id="example-prototypes-and-exemplars"><a href="#example-prototypes-and-exemplars">Example: Prototypes and Exemplars</a></h2>
<p>An important debate in psychology and philosophy has concerned the nature of <em>concepts</em>. The classical theory of concepts holds that they can defined in terms of necessary and sufficient conditions. For example, the concept <strong>dog</strong> might consist of a list of features— such as <strong>furry</strong>, <strong>barks</strong>, etc. If an object in the world matches the right features, then it is a dog.</p>
<p>However, it appears that, at least for some concepts, the classical theory faces some difficulties. For example, some concepts appear to be <em>family resemblance categories</em> (FRC). Members of a FRC share many features in commone, but the overlap is not total, and there is the possibility that two members of the category can share <em>no</em> feature in common, instead, each sharing features with <em>other</em> members of the category.</p>
<p>The philosopher Wittgenstein—who introduced the concept of Family Resemblance Categories—famously discussed the example of <em>games</em>. There are many different kinds of games: ball games, drinking games, children’s playground games, card games, video games, role-playing games, etc. It is not clear that there is a single list of features which they all share and which can uniquely identify them all as <strong>game</strong> (See: <em>Murphy, G. L. 2004. The Big Book of Concepts. The MIT Press.</em> For an in-depth discussion of many issues surrounding concepts.).</p>
<p>Two theories have emerged to explain FRCs (and other related phenomena): <em>prototype</em> theories and <em>exemplar</em> theories. In prototype theories, concepts are considered to be based on a single stored prototype. People judge whether something is an example of a concept by comparing to this stored representation. For example, the prototype for <strong>dog</strong> might include features such as <em>furry</em>, <em>barks</em>, etc. An object is a member of a category (concept) to the degree that it matches the single stored prototype.</p>
<p>In <em>exemplar theories</em>, by contrast, it is assumed that people store all examples of a particular concept, rather than a single summary representation in prototype forms. A new object is classified by comparison with all of these forms.</p>
<p>Both prototype and exemplar theories are based on similarity, and the probability that an observation is assigned to category <span class="math">\(c_{N}\)</span> can be given by <span class="math">\[p(c_{N} \mid x_N, \vec{x}_{N-1}, \vec{c}_{N-1}) = \frac{\eta_{N,j}\beta_{N,j}}{\sum_{c} \eta_{N,c}\beta_{N,c}}\]</span> where <span class="math">\(\eta_{N,i}\)</span> is the similarity between observation <span class="math">\(N\)</span> and category <span class="math">\(i\)</span>, and <span class="math">\(\beta_{N,i}\)</span> is the response bias for the category (i.e., its prior weight).</p>
<p>Exemplar models treat the similarity between observation <span class="math">\(N\)</span> and a category as a sum over all members of the category: <span class="math">\[\eta_{N,i} = \sum_{i \mid c_{i} = j } \eta_{N,i}\]</span> Prototype models treat the similarity as the similarity between observation <span class="math">\(N\)</span> and the single stored prototype: <span class="math">\[\eta_{N,i} = \eta_{N,p_i}\]</span> Notice that these two models can be seen as opposite ends of a spectrum; one estimates the category based on every member, while the other estimates based on a single member. There are clearly many intermediate points where each category can be viewed as a mixture over <span class="math">\(K\)</span> clusters.</p>
<p>Griffiths et al. (2007) show how a large number of different models of categorization can be unified by viewing them all as special cases of a HDP which learns how many clusters each category should be represented by. (Griffiths, T. L., Canini, K. R., Sanborn, A. N., and Navarro, D. J. (2007). Unifying rational models of categorization via the hierarchical dirichlet process. In Proceedings of the Twenty-Ninth Annual Conference of the Cognitive Science Society.)</p>
<p>In particular, Griffiths et al. (2007) examine the data from Smith and Minda (1998), which shows how learners undergo a transition from ptototype to exemplar representations during the course of learning. (Smith, J. D. and Minda, J. P. (1998). Prototypes in the mist: The early epochs of category learning. Journal of Experimental Psychology: Learning, Memory, and Cognition)</p>
<p>The results are shown below.</p>
<center>
<img src='images/unifying-table.png' width='500' />
</center>

<center>
<img src='images/unifying.png' width='600' />
</center>

   </div>
</div>
</body>

<script src="scripts/after-body.js"></script>
</html>
